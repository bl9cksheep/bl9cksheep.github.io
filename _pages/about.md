---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>
<br/>
Hi! I am a third-year undergraduate student at <font color=DodgerBlue>Beihang University</font>(Beijing University of Aeronautics and Astronautics).

My research interests include:
+ Multimedia Content Understanding
+ Multimodal Representation Learning
+ Misinformation Detection
  
<a href='https://scholar.google.com/citations?user=_NICS5EAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=Google Scholar Citations">

<nobr><font color=LightCoral>I'm currently applying for a PhD position for Fall 2026.</font> Feel free to contact me if you're interested in my research or just want to chat!</nobr>

My Email: <moyang_liu@buaa.edu.cn>

# 📝 Publications 

- \[**ArXiv**\]
  <span style="font-size: 1.2em; font-family: 'Palatino', 'Georgia', serif; color: #2a2a2a;">
    Deconfounded Reasoning for Multimodal Fake News Detection via Causal Intervention
  </span>

    <strong><u>Moyang Liu</u></strong>, Kaiying Yan, Yukun Liu, Ruibo Fu, Zhengqi Wen, Xuefei Liu, Chenxing Li
  
    \[<a href="https://arxiv.org/abs/2504.09163" style="color: CornflowerBlue; text-decoration: none;">🔗Paper Link</a>\] Under Review, 2025
<br/>
<div style="margin-top: 23px;"></div>
- \[**ArXiv**\]
  <span style="font-size: 1.2em; font-family: 'Palatino', 'Georgia', serif; color: #2a2a2a;">
    Exploring Modality Disruption in Multimodal Fake News Detection
  </span>

    <strong><u>Moyang Liu</u></strong>, Kaiying Yan, Yukun Liu, Ruibo Fu, Zhengqi Wen, Xuefei Liu, Chenxing Li
  
    \[<a href="https://arxiv.org/abs/2504.09154" style="color: CornflowerBlue; text-decoration: none;">🔗Paper Link</a>\] Under Review, 2025
<br/>
<div style="margin-top: 23px;"></div>
- \[**ICASSP 2025**\]
  <span style="font-size: 1.2em; font-family: 'Palatino', 'Georgia', serif; color: #2a2a2a;">
    MTPareto: A MultiModal Targeted Pareto Framework for Fake News Detection
  </span>

    Kaiying Yan, <strong><u>Moyang Liu</u></strong>, Yukun Liu, Ruibo Fu, Zhengqi Wen, Jianhua Tao, Xuefei Liu, Guanjun Li
  
    \[<a href="https://arxiv.org/abs/2501.06764" style="color: CornflowerBlue; text-decoration: none;">🔗Paper Link</a>\]
    2025 IEEE International Conference on Acoustics, Speech, and Signal Processing
<br/>
<div style="margin-top: 23px;"></div>
- \[**ISCSLP 2024**\]
  <span style="font-size: 1.2em; font-family: 'Palatino', 'Georgia', serif; color: #2a2a2a;">
    Exploring the Role of Audio in Multimodal Misinformation Detection
  </span>

    <strong><u>Moyang Liu</u></strong>, Yukun Liu, Ruibo Fu, Zhengqi Wen, Jianhua Tao, Xuefei Liu, Guanjun Li
  
    \[<a href="https://ieeexplore.ieee.org/abstract/document/10800162" style="color: CornflowerBlue; text-decoration: none;">🔗Paper Link</a>\]
    2024 IEEE 14th International Symposium on Chinese Spoken Language Processing
<br/>
<div style="margin-top: 23px;"></div>
- \[**NeurIPS 2024 Workshop**\]
  <span style="font-size: 1.2em; font-family: 'Palatino', 'Georgia', serif; color: #2a2a2a;">
    MisD-MoE: A Multimodal Misinformation Detection Framework with Adaptive Feature Selection
  </span>

    <strong><u>Moyang Liu</u></strong>, Kaiying Yan, Yukun Liu, Ruibo Fu, Zhengqi Wen, Xuefei Liu, Chenxing Li
  
    \[<a href="https://neurips2024-enlsp.github.io/papers/paper_36.pdf" style="color: CornflowerBlue; text-decoration: none;">🔗Paper Link</a>\]
    2024 NeurIPS Efficient Natural Language and Speech Processing Workshop


# 🎖 Selected Honors 

- <span style="color: #111111; font-weight: bold; font-style: italic;">Grand Prize</span>, Academic Competition Scholarship, Beihang University, 2023
- <span style="color: #111111; font-weight: bold; font-style: italic;">Grand Prize</span>, Innovation and Entrepreneurship Scholarship, Beihang University, 2024
- <span style="color: #111111; font-weight: bold; font-style: italic;">Second Prize</span>, Academic Scholarship, Beihang University, 2023
- <span style="color: #111111; font-weight: bold; font-style: italic;">Grand Prize (National Level)</span>, The 19th “Challenge Cup” National College Student Academic and Technological Innovation Competition for University Students, 2024
- <span style="color: #111111; font-weight: bold; font-style: italic;">First Prize</span>, The 14th National Undergraduate Mathematics Competition, 2022


# 📖 Education and Internships
<style>
  .edu-card {
    display: flex;
    align-items: flex-start;
    border: 1px solid #ddd;
    border-radius: 10px;
    padding: 16px;
    margin: 16px 0;
    background-color: #fff;
    font-family: sans-serif;
    color: #222;
  }

  .edu-logo {
    width: 70px;
    height: 70px;
    margin-right: 16px;
    flex-shrink: 0;
    border-radius: 8px;
  }

  .edu-content {
    font-size: 14px;
    line-height: 1.5;
  }

  .edu-content h3 {
    margin: 0;
    font-size: 16px;
  }

  .edu-content p {
    margin: 4px 0;
  }
</style>

<div class="edu-card">
  <img class="edu-logo" src="/images/beihanglogo.jpg" alt="University Logo">
  <div class="edu-content">
    <h3>Beihang University</h3>
    <p>2022.09 – Present</p>
    <p>Bachelor of Engineering in Biomedical Engineering</p>
  </div>
</div>

<div class="edu-card">
  <img class="edu-logo" src="/images/casialogo.jpg" alt="CASIA Logo">
  <div class="edu-content">
    <h3>Institute of Automation, Chinese Academy of Sciences</h3>
    <p>2024.03 – Present</p>
    <p>Research Intern</p>
  </div>
</div>

# 🌐 Language Skills

- 📘 **Mandarin Chinese** — Native
- 📗 **English** — Fluent
  - *CET-4: 653 | CET-6: 604 | IELTS: preparing*
- 📙 **Japanese** — Basic proficiency
- 📕 **Korean** — Basic proficiency


